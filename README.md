# DFSc_AZ
Deep Learning Maths

Support Vector Regression (SVR):

SVR is a regression algorithm based on Support Vector Machines (SVM), which are primarily used for classification tasks.
SVR aims to find a hyperplane that best fits the data, while simultaneously minimizing the margin violations or errors.
SVR is particularly effective when dealing with complex, non-linear relationships between features and the target variable.

It uses a kernel function to implicitly map the data to a higher-dimensional feature space, where linear regression is performed.
SVR allows for flexible model complexity through the choice of kernel functions, such as the Radial Basis Function (RBF) kernel

When to use SVR or Polynomial Regression:

SVR is a good choice when dealing with complex non-linear relationships, especially when there is no clear indication of the appropriate degree of polynomial.
SVR is useful when the dataset has high dimensionality or when the number of features is large compared to the number of samples.
Polynomial Regression is suitable when there is prior knowledge or evidence suggesting a polynomial relationship between the features and the target variable.
Polynomial Regression may work well when the relationship appears to be curved, but not necessarily complex enough to require the flexibility of SVR.
